{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr06ArfnJmWXEtXsysA0Xi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejinderpa/LANGCHAIN/blob/main/Retrieval_Augmented_Generation_Using_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HKBh74ozdXuR"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q youtube-transcript-api langchain-community faiss-cpu tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y-jyL2jeOct",
        "outputId": "09e0b1a5-0cb3-432a-b282-c3f5537f0e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/485.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.0/485.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PfvztNuKem-S",
        "outputId": "1f817f4a-6fc7-4b57-8802-1ce2e7abc099"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google_genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google_genai) (0.3.74)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google_genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google_genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google_genai-2.1.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "5eef0a3141e2457ab2e40bf585837a69"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = \"88bMVbx1dzM\""
      ],
      "metadata": {
        "id": "AyrbJ7o-0MHy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "ytt_api = YouTubeTranscriptApi()\n",
        "transcript_list = ytt_api.fetch(video_id)"
      ],
      "metadata": {
        "id": "jjfdolpt0IEi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and combine the text from the transcript list\n",
        "# Accessing the text attribute using dot notation\n",
        "transcript_text = \" \".join([d.text for d in transcript_list])\n",
        "print(\"Full Transcript Text:\")\n",
        "print(transcript_text)"
      ],
      "metadata": {
        "id": "zd6pH-z2fy_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff1c4bb-8ec2-409a-fe21-04982cb5395c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Transcript Text:\n",
            "This is a tiny piece of metal \n",
            "just three millimeters across. And here's what happens if \n",
            "you just keep zooming in: 1,000 times, 100,000 times, 50 million times. Each of these blobs is an actual atom. I saw this the other day at \n",
            "the University of Sydney, and it kind of blew my mind \n",
            "because up until just 30 years ago,   directly seeing atoms like this \n",
            "was thought to be impossible. The rooms that you're going to see here are \n",
            "perhaps the most shielded rooms on campus, or even in the whole of Sydney, I would say. And perhaps also the most expensive. That's wild. So why is it so hard to see atoms? Well, you can't actually see \n",
            "atoms with visible light. That's because while light has wavelengths \n",
            "between 380 and 750 nanometers, an atom is still over 3000 times \n",
            "smaller, just 0.1 nanometers. And if the wavelength of light is much \n",
            "bigger than the thing you're trying to see, the light will just diffract or bend \n",
            "around it so you won't be able to see it. So if you want to see atoms, you need \n",
            "something with a much, much smaller wavelength. The best candidate isn't even light. It's electrons. In 1924, a French physicist named Louis de Broglie \n",
            "worked out that everything was sort of wavelike. Not just light, but matter too. Atoms, molecules, even you \n",
            "yourself have a wavelength. And the formula for this \n",
            "wavelength is Planck's constant,   divided by the object's momentum, \n",
            "that is, mass times velocity. So here what you actually see,   that's the column of the microscope where \n",
            "we accelerate the 300 kV electrons down. 300 kilovolts, these electrons? So they are relativistic particles. How fast are they moving? \n",
            "99% of the speed of light? Around 80.\n",
            "80% the speed of light? Yeah.\n",
            "So what would be their wavelength? The wavelength is the Planck \n",
            "constant over the momentum, right? So if we calculate that, we come to \n",
            "around between 2 to 3 picometers. Whoa! That's over 100,000 times \n",
            "smaller than visible light. So theoretically, you get \n",
            "100,000 times more resolution. Shortly after de Broglie's discovery, a \n",
            "group of scientists in Germany started   working on a microscope that would \n",
            "use these high-speed electrons. The only problem is you can't \n",
            "bend electrons using glass lenses. So how do you focus them? Hans Busch, a German physicist, suggested that \n",
            "an electromagnetic lens might do the trick. He published his results in 1926, \n",
            "but never actually built one. Fortunately, a copy of his paper fell into the \n",
            "hands of an eager young PhD student, Ernst Ruska. Ruska built his first prototype by coiling up   some wire and surrounding it with iron — \n",
            "taking care to leave a gap in the middle. Then, when he passed a current through the coil,   it induced a donut-shaped magnetic field \n",
            "through the metal and across this gap. This was his lens. To test it, Ruska first boiled \n",
            "electrons off a tungsten filament,   the same kind of filament you'd \n",
            "find in an incandescent light bulb. He accelerated these free electrons through a   positively charged anode down \n",
            "to his electromagnetic lens. As an electron approaches the lens, the \n",
            "magnetic field exerts a force on it. So if an electron is traveling in the y direction \n",
            "and the magnetic fields are in the x direction, this force, called the Lorentz \n",
            "force, pushes it in the z direction. But as the electron moves this way, it encounters \n",
            "other magnetic field lines along the donut shape, which constantly point its motion in a circle. But then this circular motion means \n",
            "the Lorentz force starts pushing the   electron inwards as well, spiraling \n",
            "it into the center of the lens. Now, if you trace the path of \n",
            "the whole beam of electrons,   you'll see they all get steered \n",
            "into the center, focusing the beam. By 1931, Ruska and his colleague,\n",
            "Max Knoll, used this kind of design   to build the first working electron microscope. It was pretty basic, made of brass \n",
            "roughly bolted together, but it worked. The image itself was created once the focused   electron beam hit a sample \n",
            "sitting at the focal point. The sample needed to be incredibly \n",
            "thin, only around 100 nanometers thick. More electrons would make it through \n",
            "the thinner parts of the sample than   the thicker parts, creating an \n",
            "electron imprint of the sample. Then a second electromagnetic lens magnified this   imprint down onto a fluorescent \n",
            "detector, producing the final image. This was known as a transmission \n",
            "electron microscope or TEM. Now, early versions of the \n",
            "microscope barely magnified at all. In fact, it wasn't even better \n",
            "than an optical microscope. But Ruska was determined. Over the next few years, he experimented with   adding more lenses onto the microscope \n",
            "to create bigger and bigger images. By the mid-1930s, Ruska had gotten the \n",
            "TEM way past 10,000 times magnification. It could produce close-ups of insects, bacteria,   and even viruses at a level far \n",
            "surpassing the optical microscope. But right as Ruska's TEM was taking \n",
            "off, a German physicist named Otto Scherzer   published a paper claiming that the \n",
            "microscope was about to hit a brick wall. There was a flaw in the electromagnetic lens, \n",
            "he wrote, that was completely unavoidable. For an electron to make it \n",
            "to the focus of the lens,   it needs to be deflected by a specific amount. If you simplify its trajectory, you can define \n",
            "that ideal deflection with this angle theta. This angle depends on the horizontal distance   of the electron from the optical \n",
            "axis, and how far down the axis the focus is, also known as the focal \n",
            "length. The shorter the focal length, the stronger the magnification. If you graph this angle as a function \n",
            "of distance to the optical axis,   you'll see that it can be approximated as linear. The problem is that the magnetic \n",
            "field doesn't scale linearly. It's much stronger near the edges of the magnet. So if you plot the curve for the \n",
            "actual deflection of the electrons,   you'll see that the magnetic field \n",
            "overdeflects the electrons further out. Their angles are bigger than they should be,   so they end up focusing \n",
            "before the rays in the middle. And as a result, the focus is spread across the   optical axis instead of being \n",
            "contained in a single point. The blur starts out around the edges of the image, \n",
            "but it gets worse the higher the magnification. This is called spherical aberration, and it \n",
            "distorts every radially symmetric magnetic lens. In fact, it doesn't just affect magnetic lenses. Every spherical lens, from a camera to a telescope \n",
            "to a magnifying glass also suffers from it. But there is a surprisingly simple way to \n",
            "minimize spherical aberration. Just add   a second lens, one that diverges \n",
            "light instead of converging it. Now, a diverging lens also \n",
            "suffers from spherical aberration. But if it has the same amount of aberration \n",
            "as your converging lens just in reverse, you can stack the two to essentially \n",
            "cancel out their effects. And that removes the aberrations almost entirely. Almost all modern lens systems in cameras   and microscopes use some sort \n",
            "of correcting divergent lens. So you might imagine that the TEM \n",
            "simply needs its own version of a   diverging spherical lens to magnify further. But with magnets, this is physically impossible. Every magnet has two poles, a North and a \n",
            "South. It's impossible to just have one. Even if you split a magnet down the middle,   it creates two smaller magnets, \n",
            "both with a North and South. And all magnetic field lines have to start at one \n",
            "pole and end at the other, forming a closed loop. It's a direct result of the second \n",
            "Maxwell equation because the field   that you create has field lines that \n",
            "start and end at the same magnet. So the electrons will always \n",
            "cross through two lines. The first time it passes through, by the Lorentz \n",
            "force, it's brought into the spiraling motion. And then the second time \n",
            "from that spiraling motion,   which has then a slightly different \n",
            "direction, it's pushed towards the axis. That's why all electromagnetic lenses by default \n",
            "will converge that beam, and never diverge it. Even if you shot electrons in from the other \n",
            "side of the lens, they would still get focused. This is what Otto Scherzer's paper proved \n",
            "in 1936, stopping progress on the TEM. It is impossible to produce a radially \n",
            "symmetric magnetic lens that diverges. And this was, of course, a big roadblock \n",
            "for the development of electron microscopy, because people saw, okay, we can \n",
            "accelerate electrons as much as we want, the presence of spherical aberration \n",
            "will always be in the way. Because of this roadblock, advancements in the \n",
            "microscope's resolution slowed significantly. By 1955, another microscope \n",
            "beat the TEM to the punch and   took the first generally accepted image of atoms. This was called the field ion microscope,   and it worked by shooting helium or neon \n",
            "atoms at an atomically sharp needle tip. The tip was positively charged. So \n",
            "when the gas atoms hit the needle,   they got ionized and were ejected \n",
            "off perpendicular to the surface. And that could form an impression \n",
            "of the atomic structure of the tip. But this method was limited. You could only get a sense of the atomic \n",
            "structure of the very tip of the needle. And the images weren't all that impressive. Luckily, Ruska's electron microscope   wouldn't stay stuck in the realm \n",
            "of insects and bacteria forever. Now, you might not be an insect getting \n",
            "bombarded with relativistic electrons, but it can sometimes feel \n",
            "like it when you're getting   bombarded with spam calls and targeted ads. It's a real problem when we're \n",
            "researching for our videos. I was reading up on lenses and optics,   and a few days later I started getting \n",
            "targeted ads for glasses and eye surgery. So someone out there is probably \n",
            "selling my browsing data. But this is where today's \n",
            "sponsor, Incogni, comes in. With your permission, Incogni will fight the data   brokers on your behalf by finding out \n",
            "who has your data, which laws apply,   and then they request, with the appropriate \n",
            "legal language, your information be deleted. You just sign up and they'll give you a list of \n",
            "all the companies that have your information,   how severe each claim is, and \n",
            "the status of all your requests. Now, I signed up last April, and since \n",
            "then they filed 317 requests for me,   281 of which have been completed, \n",
            "saving me over 210 hours of work. And now I'm no longer getting \n",
            "ads for glasses I don't need. So to try it Incogni and fight against the \n",
            "data brokers, visit Incogni.com/Veritasium. You can also click the link in the \n",
            "description or scan this QR code. Make sure to use the code Veritasium to get 60%   off your annual subscription to \n",
            "take control of your data today. That's Incogni.com/Veritasium. And now back to the electron microscope. Despite Scherzer's aberration limit \n",
            "work on the transmission electron microscope continued. During the next four decades. People tried boosting the resolution with \n",
            "clever workarounds, and perhaps none more   so than British-American physicist Albert Crewe. His idea was to replace the tungsten filament,   which fired off electrons at \n",
            "random, with a more directed source. So instead of boiling electrons off the surface,   he tried pulling them off with \n",
            "a stronger electric field. And, by sharpening the tungsten into a fine tip,   he was able to create a narrow beam which was \n",
            "over a thousand times brighter than before. He paired his new narrow beam \n",
            "with an unlikely technology. The cathode ray tube TV. These TVs worked by scanning an \n",
            "electron beam across a screen. The   screen was coated in a phosphor that \n",
            "produced light when hit by electrons. And by varying the intensity of the electron beam,   you could vary the brightness of the \n",
            "screen, giving you a black-and-white image. Crewe was inspired to design a \n",
            "similar electron beam for the TEM that would scan across the nanoscopic sample. So instead of creating an imprint \n",
            "of the whole sample at once, Crewe's electron beam made smaller imprints, \n",
            "mapping the sample out bit by bit. This wasn't the first time someone had \n",
            "tried to make a scanning version of the TEM. German researcher Manfred von Ardenne \n",
            "built an early prototype in the 1930s,   but it was destroyed during WWII. When Crewe revived Ardenne's design, \n",
            "he made several drastic improvements,   and by 1970 he had this. The first image of single atoms \n",
            "taken with the electron microscope. Researchers quickly jumped to employ his \n",
            "tech, producing countless images of atoms. After nearly a century of improvements \n",
            "from Ruska, Crewe, and many others,   the magnification upgrades on \n",
            "the TEM had reached their peak. But Scherzer's problem persisted. Spherical aberration set a hard \n",
            "limit on how small you could see. Even Crewe himself gave up on trying to \n",
            "get around it after over ten years of work. \"Unfortunately, we could never make it \n",
            "work. After many heartbreaking attempts,   we were forced to admit defeat.\" Around this time, other microscopes \n",
            "emerged that could also image atoms. These probe microscopes work by gliding an \n",
            "incredibly small stylus across the sample. The stylus detects variations in quantum effects   or nanoscale forces to then map the \n",
            "surface structure of the sample. These were easier to build, and \n",
            "because they didn't use any lenses,   they weren't limited by spherical aberration. Their images were even 3D. But the looming issue was that \n",
            "these probes weren't really   seeing atoms. It was more like feeling atoms. Throughout the 80s and 90s, this was all we had. But what if there was another way? Scherzer's theorem proof that a diverging, \n",
            "radially symmetric lens isn't possible. But if you're willing to give up on that \n",
            "symmetry, well, the theorem no longer applies. The problem is that radial symmetry is \n",
            "arguably the most important property of   any lens, because if you break the \n",
            "symmetry, you also break the image. But three maverick scientists \n",
            "thought there might be a way. Knut Urban, Max Haider, and Harold Rose were known   in the electron microscope \n",
            "community as troublemakers, and for years barely anyone had been \n",
            "interested in their research or,   more importantly, in funding it. And for a good reason too. \n",
            "Their idea was kind of crazy. I mean, they purposely wanted to break the \n",
            "image using a lens that wasn't symmetric. Their hope was that there would be a small part   of this distorted image that \n",
            "would be slightly diverging. And maybe, just maybe, this \n",
            "small part could correct the   spherical aberration of the original lens. So they got to work To distort the image, they used a massive nest \n",
            "of electromagnets with six,   eight, or even ten separate coils and \n",
            "magnets with bumpy magnetic fields. These were known as the hexapole, \n",
            "octopole, and decapole magnets. So as the electron beam passed through a hexapole,   it would twist and squeeze the flat \n",
            "2D image into a triangular saddle. And the circumference of the original beam \n",
            "would be pushed into the three corners,   with the rest of the interior stretched out. But now the middle of the image \n",
            "would have a slight concave bow,   giving the effect of a small divergence. Then Rose, Haider, and Urban forced the \n",
            "beam through a second hexapole , one that worked   the opposite way, so it would unbend the \n",
            "distorted image back into a circular shape. But now they, calculated this \n",
            "new image might have the remnants   of that tiny divergence still in its center, with \n",
            "spherical aberration pointing in the opposite way. So if they got their maths and engineering \n",
            "exactly right, they could feed an image with   spherical aberration through these two lenses \n",
            "to almost completely counteract the effect. And I imagine a lot of people in the field thought \n",
            "it was a crazy idea when it was proposed, right? Not only the concept, but, that this is, \n",
            "like, technically feasible, I believe.  It was thought that this is not possible. By May 1997, the group had just two months of   development time left before their \n",
            "last sponsor withdrew their backing. And to make matters worse, their latest lens \n",
            "iteration was still just on the drawing board. But somehow, by the 23rd of July,   just a week before their funding ran \n",
            "out, the new lens was ready to test. They gingerly placed it into the microscope,   but like every time before it, \n",
            "the lens was unstable and failed. So they decided to switch off the equipment \n",
            "for 24 hours to allow the magnets to settle. And then at 2 a.m. on the \n",
            "24th, they turned it on again,   and almost magically, the \n",
            "picture started to stabilize. Suddenly, there was no aberration. \n",
            "Only beautiful, clear images of atoms. After more than 60 years of failed attempts,   Urban, Rose, and Haider pulled \n",
            "off the seemingly impossible. With this method, they cut the resolution \n",
            "of the TEM down to only 0.13 nanometers. An average TEM image went from \n",
            "looking like this to this. A few months after the group's breakthrough,   Knut Urban attended a microscopy \n",
            "conference to share these results. But because of the group's reputation,   he was relegated to a small back \n",
            "room that barely anyone noticed. Soon, however, word spread that against all odds,   his pictures seemed real. Then \n",
            "a crowd of hundreds formed. People were lining up outside, hoping to get \n",
            "a glimpse of their stunningly sharp images. So we're going to get a sample holder. Yeah, so we got a sample holder out. We put that under the optical microscope. So the sample itself is a small lamella that \n",
            "you can't see without the optical microscope. Yeah.\n",
            "Have a look through that. Beautiful. On top of the B there's \n",
            "a prong. Yeah. And on the very top   of that on the left-hand side, \n",
            "looks like a little bit of dust. That's our actual sample. Okay, now I simply go up with the magnification \n",
            "and I do a very few, like, more basic alignments.   In this electron microscope because it's \n",
            "called transmission electron microscope, the electrons always transmit the sample. Here we  look through our entire sample at the same time.  And that's why it's so important \n",
            "that we align the sample. If you imagine atoms in a high-symmetry \n",
            "direction are lined up like pearls on a string. When we look down it, well, we can see an image. But if we are in, like, some random direction \n",
            "that everything would be just blurred. So that's why we have to do \n",
            "some tilting in the edge. And this is where the actual sample \n",
            "starts — the strontium titanate. And this is a thin region where we \n",
            "hope to get atomic resolution. So this is 5000 times? Yes Wow. And we see strontium, titanium. We see \n",
            "oxygen. We see carbon. That's contamination. So most likely what we're looking \n",
            "at is carbon contamination. When you do this focus, what \n",
            "are you really looking for? I look for this edge to become sharp. See atoms. What? Just like that. That's wild.   Shortly after, the group successfully corrected   \n",
            "Orndrej Krivanek independently achieved   the same for Crewe’s version of \n",
            "the microscope, the scanning TEM. And in 2020, all four were awarded \n",
            "the prestigious Kavli Prize in   Nanoscience for accomplishing what \n",
            "so many others thought impossible. Through their persistence and ingenuity, \n",
            "seeing atoms like this is, well, normal. How big of a difference does \n",
            "aberration correction make? If you want to see atoms and if you want to, \n",
            "for example, measure in atomic distances,   and if you want to learn what type of atoms \n",
            "you have, you need aberration correction. Any research that's material science. \n",
            "Materials engineering, chemical engineering... You need to see what's happening at the atomic  level because you want to relate \n",
            "the properties to the structure. If you can't see the structure at the atomic \n",
            "level, you only have half of the information. So that was a game changer. That's why nowadays every university in \n",
            "principle needs a microscope like that.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "BsJrpu8L00xo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "# Use the split_text method on the combined transcript_text string\n",
        "chunks = splitter.split_text(transcript_text)\n",
        "\n",
        "# Optional: If you want to create LangChain Document objects from the chunks\n",
        "# from langchain_core.documents import Document\n",
        "# chunks_as_documents = [Document(page_content=chunk) for chunk in chunks]\n",
        "\n",
        "print(f\"Split the transcript into {len(chunks)} chunks.\")\n",
        "# print(chunks[:5]) # Display the first few chunks to verify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kqluuYQ0agJ",
        "outputId": "348ce010-95be-4b01-d37a-d0fff6568970"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split the transcript into 25 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[24]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "lEb5E19602VP",
        "outputId": "78d43969-f13a-4035-b6eb-faae3c06e9fd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"aberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that's material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what's happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can't see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That's why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.documents import Document # Import Document\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Convert string chunks to Document objects\n",
        "chunks_as_documents = [Document(page_content=chunk) for chunk in chunks]\n",
        "\n",
        "vectorindex_google = FAISS.from_documents(chunks_as_documents, embeddings)"
      ],
      "metadata": {
        "id": "-tKdyelM1Zo5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorindex_google.index_to_docstore_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF1UKJgp1dte",
        "outputId": "b67f37f0-7571-40b2-9c3b-d843a35e1e16"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'e42831b3-c6d7-49ad-a21d-a9890d37d23a',\n",
              " 1: 'dce4a31e-d547-4194-bff1-3746daf9a12f',\n",
              " 2: 'b1bb928a-a54d-4978-b7a1-346ebbb36451',\n",
              " 3: '09a139b7-4aa1-4a32-af31-e05b13a7085b',\n",
              " 4: '6bd18750-1d1c-47f3-a2e1-433a3d4048ca',\n",
              " 5: '35f2f4c2-1614-4b53-90ce-8cc9b170ea96',\n",
              " 6: 'dcb1bf79-b903-4668-81c5-89354057740f',\n",
              " 7: 'fbca9b4e-a065-4032-b457-4a7f628284a7',\n",
              " 8: '84c1e0ad-393c-46ce-ba2f-7976c7c293ae',\n",
              " 9: '5da2295f-5549-486b-a545-17998ad7a8cd',\n",
              " 10: '542cb9d8-d679-456f-bc39-a327d54d26bd',\n",
              " 11: 'e8785b0f-0cf1-44f2-a53e-b98a020573ec',\n",
              " 12: '0dfbcb67-6c4f-49c2-8251-1aa9a4da6f71',\n",
              " 13: '97cdba99-ef9b-4f28-a032-3db1e3c0e660',\n",
              " 14: 'bdeb8924-977b-4fdd-8d90-7aea98ee6d72',\n",
              " 15: 'c8e58fd5-95d9-49dd-882b-7e1c89c3f72b',\n",
              " 16: '4b1820e8-4986-410c-9393-e040a4413d2a',\n",
              " 17: '8398cd6c-be72-41dc-88ab-558956662cbd',\n",
              " 18: '0d3d55f2-d650-4937-9bfd-e827fcfb836b',\n",
              " 19: '8b5edcd7-52dd-4967-bac4-52ba79fb5520',\n",
              " 20: '99740c5c-638b-4a29-9193-fe1018b16d71',\n",
              " 21: 'f4dc5735-4e8c-4b7f-a55f-fa9198af0b0e',\n",
              " 22: '646bed4b-34fd-4080-94aa-13ab8c3973d0',\n",
              " 23: 'c9f346dd-b1f8-49ed-8a98-b5cccb012ed4',\n",
              " 24: '2b595ed1-01ac-489e-a2da-7e83216cd04a'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorindex_google.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "LmFLh0SO2Rki"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fieS3suo2cde",
        "outputId": "073d0cfd-03be-4737-b3c1-b84b7775140b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7b259ca52810>, search_kwargs={'k': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"What is deepmind\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_rP9stR2dke",
        "outputId": "e196bf90-a544-42f8-b15c-ad4a2fa40b0e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2b595ed1-01ac-489e-a2da-7e83216cd04a', metadata={}, page_content=\"aberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that's material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what's happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can't see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That's why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\"),\n",
              " Document(id='e8785b0f-0cf1-44f2-a53e-b98a020573ec', metadata={}, page_content=\"when the gas atoms hit the needle,\\xa0\\xa0 they got ionized and were ejected\\xa0\\noff perpendicular to the surface. And that could form an impression\\xa0\\nof the atomic structure of the tip. But this method was limited. You could only get a sense of the atomic\\xa0\\nstructure of the very tip of the needle. And the images weren't all that impressive. Luckily, Ruska's electron microscope\\xa0\\xa0 wouldn't stay stuck in the realm\\xa0\\nof insects and bacteria forever. Now, you might not be an insect getting\\xa0\\nbombarded with relativistic electrons, but it can sometimes feel\\xa0\\nlike it when you're getting\\xa0\\xa0 bombarded with spam calls and targeted ads. It's a real problem when we're\\xa0\\nresearching for our videos. I was reading up on lenses and optics,\\xa0\\xa0 and a few days later I started getting\\xa0\\ntargeted ads for glasses and eye surgery. So someone out there is probably\\xa0\\nselling my browsing data. But this is where today's\"),\n",
              " Document(id='35f2f4c2-1614-4b53-90ce-8cc9b170ea96', metadata={}, page_content=\"sitting at the focal point. The sample needed to be incredibly\\xa0\\nthin, only around 100 nanometers thick. More electrons would make it through\\xa0\\nthe thinner parts of the sample than\\xa0\\xa0 the thicker parts, creating an\\xa0\\nelectron imprint of the sample. Then a second electromagnetic lens magnified this\\xa0\\xa0 imprint down onto a fluorescent\\xa0\\ndetector, producing the final image. This was known as a transmission\\xa0\\nelectron microscope or TEM. Now, early versions of the\\xa0\\nmicroscope barely magnified at all. In fact, it wasn't even better\\xa0\\nthan an optical microscope. But Ruska was determined. Over the next few years, he experimented with\\xa0\\xa0 adding more lenses onto the microscope\\xa0\\nto create bigger and bigger images. By the mid-1930s, Ruska had gotten the\\xa0\\nTEM way past 10,000 times magnification. It could produce close-ups of insects, bacteria,\\xa0\\xa0 and even viruses at a level far\\xa0\\nsurpassing the optical microscope. But right as Ruska's TEM was taking\"),\n",
              " Document(id='f4dc5735-4e8c-4b7f-a55f-fa9198af0b0e', metadata={}, page_content=\"of the TEM down to only 0.13 nanometers. An average TEM image went from\\xa0\\nlooking like this to this. A few months after the group's breakthrough,\\xa0\\xa0 Knut Urban attended a microscopy\\xa0\\nconference to share these results. But because of the group's reputation,\\xa0\\xa0 he was relegated to a small back\\xa0\\nroom that barely anyone noticed. Soon, however, word spread that against all odds,\\xa0\\xa0 his pictures seemed real. Then\\xa0\\na crowd of hundreds formed. People were lining up outside, hoping to get\\xa0\\na glimpse of their stunningly sharp images. So we're going to get a sample holder. Yeah, so we got a sample holder out. We put that under the optical microscope. So the sample itself is a small lamella that\\xa0\\nyou can't see without the optical microscope. Yeah.\\nHave a look through that. Beautiful. On top of the B there's\\xa0\\na prong. Yeah. And on the very top\\xa0\\xa0 of that on the left-hand side,\\xa0\\nlooks like a little bit of dust. That's our actual sample. Okay, now I simply go up with the magnification\")]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "8_7JR8Bm2hHK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ],
      "metadata": {
        "id": "iDwyK6v-2uvw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
        "retrieved_docs    = retriever.invoke(question)"
      ],
      "metadata": {
        "id": "JvTfNeGE29DU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOucxm5o2_n_",
        "outputId": "5dc12418-b5c2-43a4-fb66-a1910f5ff2e1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2b595ed1-01ac-489e-a2da-7e83216cd04a', metadata={}, page_content=\"aberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that's material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what's happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can't see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That's why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\"),\n",
              " Document(id='8b5edcd7-52dd-4967-bac4-52ba79fb5520', metadata={}, page_content='beam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this\\xa0\\nnew image might have the remnants\\xa0\\xa0 of that tiny divergence still in its center, with\\xa0\\nspherical aberration pointing in the opposite way. So if they got their maths and engineering\\xa0\\nexactly right, they could feed an image with\\xa0\\xa0 spherical aberration through these two lenses\\xa0\\nto almost completely counteract the effect. And I imagine a lot of people in the field thought\\xa0\\nit was a crazy idea when it was proposed, right? Not only the concept, but, that this is,\\xa0\\nlike, technically feasible, I believe.\\xa0 It was thought that this is not possible. By May 1997, the group had just two months of\\xa0\\xa0 development time left before their\\xa0\\nlast sponsor withdrew their backing. And to make matters worse, their latest lens'),\n",
              " Document(id='0d3d55f2-d650-4937-9bfd-e827fcfb836b', metadata={}, page_content='would be slightly diverging. And maybe, just maybe, this\\xa0\\nsmall part could correct the\\xa0\\xa0 spherical aberration of the original lens. So they got to work To distort the image, they used a massive nest\\xa0\\nof electromagnets with six,\\xa0\\xa0 eight, or even ten separate coils and\\xa0\\nmagnets with bumpy magnetic fields. These were known as the hexapole,\\xa0\\noctopole, and decapole magnets. So as the electron beam passed through a hexapole,\\xa0\\xa0 it would twist and squeeze the flat\\xa0\\n2D image into a triangular saddle. And the circumference of the original beam\\xa0\\nwould be pushed into the three corners,\\xa0\\xa0 with the rest of the interior stretched out. But now the middle of the image\\xa0\\nwould have a slight concave bow,\\xa0\\xa0 giving the effect of a small divergence. Then Rose, Haider, and Urban forced the\\xa0\\nbeam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this'),\n",
              " Document(id='646bed4b-34fd-4080-94aa-13ab8c3973d0', metadata={}, page_content=\"a prong. Yeah. And on the very top\\xa0\\xa0 of that on the left-hand side,\\xa0\\nlooks like a little bit of dust. That's our actual sample. Okay, now I simply go up with the magnification\\xa0\\nand I do a very few, like, more basic alignments.\\xa0\\xa0 In this electron microscope because it's\\xa0\\ncalled transmission electron microscope, the electrons always transmit the sample. Here we\\xa0 look through our entire sample at the same time.  And that's why it's so important\\xa0\\nthat we align the sample. If you imagine atoms in a high-symmetry\\xa0\\ndirection are lined up like pearls on a string. When we look down it, well, we can see an image. But if we are in, like, some random direction\\xa0\\nthat everything would be just blurred. So that's why we have to do\\xa0\\nsome tilting in the edge. And this is where the actual sample\\xa0\\nstarts — the strontium titanate. And this is a thin region where we\\xa0\\nhope to get atomic resolution. So this is 5000 times? Yes Wow. And we see strontium, titanium. We see\")]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "context_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "O3erIebz3CGL",
        "outputId": "bfcf3391-4a53-4528-9bb5-5baa47564bd1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"aberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that's material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what's happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can't see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That's why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\\n\\nbeam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this\\xa0\\nnew image might have the remnants\\xa0\\xa0 of that tiny divergence still in its center, with\\xa0\\nspherical aberration pointing in the opposite way. So if they got their maths and engineering\\xa0\\nexactly right, they could feed an image with\\xa0\\xa0 spherical aberration through these two lenses\\xa0\\nto almost completely counteract the effect. And I imagine a lot of people in the field thought\\xa0\\nit was a crazy idea when it was proposed, right? Not only the concept, but, that this is,\\xa0\\nlike, technically feasible, I believe.\\xa0 It was thought that this is not possible. By May 1997, the group had just two months of\\xa0\\xa0 development time left before their\\xa0\\nlast sponsor withdrew their backing. And to make matters worse, their latest lens\\n\\nwould be slightly diverging. And maybe, just maybe, this\\xa0\\nsmall part could correct the\\xa0\\xa0 spherical aberration of the original lens. So they got to work To distort the image, they used a massive nest\\xa0\\nof electromagnets with six,\\xa0\\xa0 eight, or even ten separate coils and\\xa0\\nmagnets with bumpy magnetic fields. These were known as the hexapole,\\xa0\\noctopole, and decapole magnets. So as the electron beam passed through a hexapole,\\xa0\\xa0 it would twist and squeeze the flat\\xa0\\n2D image into a triangular saddle. And the circumference of the original beam\\xa0\\nwould be pushed into the three corners,\\xa0\\xa0 with the rest of the interior stretched out. But now the middle of the image\\xa0\\nwould have a slight concave bow,\\xa0\\xa0 giving the effect of a small divergence. Then Rose, Haider, and Urban forced the\\xa0\\nbeam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this\\n\\na prong. Yeah. And on the very top\\xa0\\xa0 of that on the left-hand side,\\xa0\\nlooks like a little bit of dust. That's our actual sample. Okay, now I simply go up with the magnification\\xa0\\nand I do a very few, like, more basic alignments.\\xa0\\xa0 In this electron microscope because it's\\xa0\\ncalled transmission electron microscope, the electrons always transmit the sample. Here we\\xa0 look through our entire sample at the same time.  And that's why it's so important\\xa0\\nthat we align the sample. If you imagine atoms in a high-symmetry\\xa0\\ndirection are lined up like pearls on a string. When we look down it, well, we can see an image. But if we are in, like, some random direction\\xa0\\nthat everything would be just blurred. So that's why we have to do\\xa0\\nsome tilting in the edge. And this is where the actual sample\\xa0\\nstarts — the strontium titanate. And this is a thin region where we\\xa0\\nhope to get atomic resolution. So this is 5000 times? Yes Wow. And we see strontium, titanium. We see\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
      ],
      "metadata": {
        "id": "X3SkWBcA3FAW"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgymkSr03HRX",
        "outputId": "8869e016-d323-4b5e-a741-d1ea8bbfff0b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text=\"\\n      You are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n      aberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that's material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what's happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can't see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That's why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\\n\\nbeam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this\\xa0\\nnew image might have the remnants\\xa0\\xa0 of that tiny divergence still in its center, with\\xa0\\nspherical aberration pointing in the opposite way. So if they got their maths and engineering\\xa0\\nexactly right, they could feed an image with\\xa0\\xa0 spherical aberration through these two lenses\\xa0\\nto almost completely counteract the effect. And I imagine a lot of people in the field thought\\xa0\\nit was a crazy idea when it was proposed, right? Not only the concept, but, that this is,\\xa0\\nlike, technically feasible, I believe.\\xa0 It was thought that this is not possible. By May 1997, the group had just two months of\\xa0\\xa0 development time left before their\\xa0\\nlast sponsor withdrew their backing. And to make matters worse, their latest lens\\n\\nwould be slightly diverging. And maybe, just maybe, this\\xa0\\nsmall part could correct the\\xa0\\xa0 spherical aberration of the original lens. So they got to work To distort the image, they used a massive nest\\xa0\\nof electromagnets with six,\\xa0\\xa0 eight, or even ten separate coils and\\xa0\\nmagnets with bumpy magnetic fields. These were known as the hexapole,\\xa0\\noctopole, and decapole magnets. So as the electron beam passed through a hexapole,\\xa0\\xa0 it would twist and squeeze the flat\\xa0\\n2D image into a triangular saddle. And the circumference of the original beam\\xa0\\nwould be pushed into the three corners,\\xa0\\xa0 with the rest of the interior stretched out. But now the middle of the image\\xa0\\nwould have a slight concave bow,\\xa0\\xa0 giving the effect of a small divergence. Then Rose, Haider, and Urban forced the\\xa0\\nbeam through a second hexapole , one that worked\\xa0\\xa0 the opposite way, so it would unbend the\\xa0\\ndistorted image back into a circular shape. But now they, calculated this\\n\\na prong. Yeah. And on the very top\\xa0\\xa0 of that on the left-hand side,\\xa0\\nlooks like a little bit of dust. That's our actual sample. Okay, now I simply go up with the magnification\\xa0\\nand I do a very few, like, more basic alignments.\\xa0\\xa0 In this electron microscope because it's\\xa0\\ncalled transmission electron microscope, the electrons always transmit the sample. Here we\\xa0 look through our entire sample at the same time.  And that's why it's so important\\xa0\\nthat we align the sample. If you imagine atoms in a high-symmetry\\xa0\\ndirection are lined up like pearls on a string. When we look down it, well, we can see an image. But if we are in, like, some random direction\\xa0\\nthat everything would be just blurred. So that's why we have to do\\xa0\\nsome tilting in the edge. And this is where the actual sample\\xa0\\nstarts — the strontium titanate. And this is a thin region where we\\xa0\\nhope to get atomic resolution. So this is 5000 times? Yes Wow. And we see strontium, titanium. We see\\n      Question: is the topic of nuclear fusion discussed in this video? if yes then what was discussed\\n    \")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step-4-Generation"
      ],
      "metadata": {
        "id": "dX4_Z8Ym3Lcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = llm.invoke(final_prompt)\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhOWjCoT3I31",
        "outputId": "3881b2f5-ea98-4485-8537-965d8aaca000"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, the provided text does not discuss nuclear fusion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building a chain"
      ],
      "metadata": {
        "id": "Lp5q_B5m3X4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "HzgUfhiS3Trh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ],
      "metadata": {
        "id": "N_0e_zpR3b1i"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ],
      "metadata": {
        "id": "PnHfPGcS3dmJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain.invoke('Why it is hard to see atoms')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unjel0yw3gWM",
        "outputId": "6845f686-2696-450a-e4ce-d99e5c030782"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'This is a tiny piece of metal\\xa0\\njust three millimeters across. And here\\'s what happens if\\xa0\\nyou just keep zooming in: 1,000 times, 100,000 times, 50 million times. Each of these blobs is an actual atom. I saw this the other day at\\xa0\\nthe University of Sydney, and it kind of blew my mind\\xa0\\nbecause up until just 30 years ago,\\xa0\\xa0 directly seeing atoms like this\\xa0\\nwas thought to be impossible. The rooms that you\\'re going to see here are\\xa0\\nperhaps the most shielded rooms on campus, or even in the whole of Sydney, I would say. And perhaps also the most expensive. That\\'s wild. So why is it so hard to see atoms? Well, you can\\'t actually see\\xa0\\natoms with visible light. That\\'s because while light has wavelengths\\xa0\\nbetween 380 and 750 nanometers, an atom is still over 3000 times\\xa0\\nsmaller, just 0.1 nanometers. And if the wavelength of light is much\\xa0\\nbigger than the thing you\\'re trying to see, the light will just diffract or bend\\n\\naberration correction make? If you want to see atoms and if you want to,\\xa0\\nfor example, measure in atomic distances,\\xa0\\xa0 and if you want to learn what type of atoms\\xa0\\nyou have, you need aberration correction. Any research that\\'s material science.\\xa0\\nMaterials engineering, chemical engineering... You need to see what\\'s happening at the atomic\\xa0\\xa0level because you want to relate\\xa0\\nthe properties to the structure. If you can\\'t see the structure at the atomic\\xa0\\nlevel, you only have half of the information. So that was a game changer. That\\'s why nowadays every university in\\xa0\\nprinciple needs a microscope like that.\\n\\nsmaller, just 0.1 nanometers. And if the wavelength of light is much\\xa0\\nbigger than the thing you\\'re trying to see, the light will just diffract or bend\\xa0\\naround it so you won\\'t be able to see it. So if you want to see atoms, you need\\xa0\\nsomething with a much, much smaller wavelength. The best candidate isn\\'t even light. It\\'s electrons. In 1924, a French physicist named Louis de Broglie\\xa0\\nworked out that everything was sort of wavelike. Not just light, but matter too. Atoms, molecules, even you\\xa0\\nyourself have a wavelength. And the formula for this\\xa0\\nwavelength is Planck\\'s constant,\\xa0\\xa0 divided by the object\\'s momentum,\\xa0\\nthat is, mass times velocity. So here what you actually see,\\xa0\\xa0 that\\'s the column of the microscope where\\xa0\\nwe accelerate the 300 kV electrons down. 300 kilovolts, these electrons? So they are relativistic particles. How fast are they moving?\\xa0\\n99% of the speed of light? Around 80.\\n80% the speed of light? Yeah.\\nSo what would be their wavelength? The wavelength is the Planck\\n\\nget around it after over ten years of work. \"Unfortunately, we could never make it\\xa0\\nwork. After many heartbreaking attempts,\\xa0\\xa0 we were forced to admit defeat.\" Around this time, other microscopes\\xa0\\nemerged that could also image atoms. These probe microscopes work by gliding an\\xa0\\nincredibly small stylus across the sample. The stylus detects variations in quantum effects\\xa0\\xa0 or nanoscale forces to then map the\\xa0\\nsurface structure of the sample. These were easier to build, and\\xa0\\nbecause they didn\\'t use any lenses,\\xa0\\xa0 they weren\\'t limited by spherical aberration. Their images were even 3D. But the looming issue was that\\xa0\\nthese probes weren\\'t really\\xa0\\xa0 seeing atoms. It was more like feeling atoms. Throughout the 80s and 90s, this was all we had. But what if there was another way? Scherzer\\'s theorem proof that a diverging,\\xa0\\nradially symmetric lens isn\\'t possible. But if you\\'re willing to give up on that\\xa0\\nsymmetry, well, the theorem no longer applies. The problem is that radial symmetry is',\n",
              " 'question': 'Why it is hard to see atoms'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "HWFE4RkZ3fKc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ],
      "metadata": {
        "id": "qDdDzZeC3kHL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain.invoke(\"Why it is hard to see atoms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "-ixSuqPk3pH6",
        "outputId": "6a11ef9a-b291-42e9-dfc2-cb725e0c56ae"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It is hard to see atoms because visible light has wavelengths between 380 and 750 nanometers, while an atom is over 3000 times smaller (0.1 nanometers).  If the wavelength of light is much bigger than what you're trying to see, the light will diffract or bend around it, making it impossible to see.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zphzZsHK3txn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}